
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Distance sampling (DS) &#8212; Remote Camera Decision Support Tool - Concept Library</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/colours.css?v=26cc69e2" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=69e22578" />
    <link rel="stylesheet" type="text/css" href="../_static/tippy.css?v=a7d99af9" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/03_20_mod_ds';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="distance-sampling-ds">
<span id="i-mod-ds"></span><h1>Distance sampling (DS)<a class="headerlink" href="#distance-sampling-ds" title="Link to this heading">#</a></h1>
<!--
:::{hint}
replace me with text
:::
-->
<p><strong>Distance sampling (DS) model (Howe et al., 2017)</strong>: A method to estimate abundance by using distances at which animals are detected (from survey lines or points) to model abundance as a function of decreasing detection probability with animal distance from the camera (using a decay function) (Cappelle et al., 2021; Howe et al., 2017).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Assumptions, Pros, Cons</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Assumptions</div>
<ul class="simple">
<li><p class="sd-card-text">Random or systematic random placements (consistent with the assumption that points are placed independently of animal locations) (Howe et al., 2017)</p></li>
<li><p class="sd-card-text"><a href="09_glossary.html#cam_location" target="_blank" data-bs-toggle="tooltip" data-bs-title="The location where a single camera was placed (recorded as 'Camera Location Name').">Camera locations<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a>  are <a href="09_glossary.html#sampledesign_random" target="_blank" data-bs-toggle="tooltip" data-bs-title="Cameras occur at randomized camera locations (or sample stations) across the area of interest, sometimes with a predetermined minimum distance between camera locations (or sample stations).">randomly placed<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a>  relative to animal movement (Palencia et al., 2021)</p></li>
<li><p class="sd-card-text">Detection is perfect (<a href="09_glossary.html#detection_probability" target="_blank" data-bs-toggle="tooltip" data-bs-title="The probability (likelihood) that an individual of the population of interest is included in the count at time or location *i*.">detection probability<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a>  ‘<em>p</em>’ =  1) at focal area */ distance 0 (Palencia et al., 2021)</p></li>
<li><p class="sd-card-text">Demographic closure (i.e., no births or deaths) and geographic closure (i.e., no immigration or emigration) (animal  is constant during the <a href="09_glossary.html#survey" target="_blank" data-bs-toggle="tooltip" data-bs-title="A unique deployment period (temporal extent) within a project (recorded as 'Survey Name').">survey<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> ) (Palencia et al., 2021)</p></li>
<li><p class="sd-card-text">Animal movement and behaviour are unaffected by the cameras (Palencia et al., 2021)</p></li>
<li><p class="sd-card-text">Animals are detected at initial locations (e.g., they do not change course in response to the camera prior to detection) (Palencia et al., 2021)</p></li>
<li><p class="sd-card-text">Distances are measured exactly (however if the data from different distances will be grouped (‘binned’) for analysis later, an accuracy of +*/- 1m may suffice) (Palencia et al., 2021)</p></li>
<li><p class="sd-card-text"><a href="09_glossary.html#independent_detections" target="_blank" data-bs-toggle="tooltip" data-bs-title="Detections that are deemed to be independent based on a user-defined threshold (e.g., 30 minutes).">Detections are independent<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a>  (Palencia et al., 2021)</p></li>
<li><p class="sd-card-text">Snapshot moments selected independently of animal locations (Palencia et al., 2021)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Pros</div>
<ul class="simple">
<li><p class="sd-card-text">A shortcut to controlling for variation in detection distances by only counting individuals within a short distance with an unobstructed view, and well sampled across cameras and species (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text"> estimates are unbiased by animal movement ‘since camera-animal distance is measured at a certain instant in time (intervals of duration <em>t</em> apart)’ (Howe et al., 2017; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Can be applied to low- populations (Howe et al., 2017; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Does not require individual identification (Howe et al., 2017)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Cons</div>
<ul class="simple">
<li><p class="sd-card-text">May require discarding a portion of the dataset (when the best fitting model truncates the dataset) (Wearn &amp; Glover-Kapfer, 2017)</p></li>
<li><p class="sd-card-text"><a href="09_glossary.html#bias" target="_blank" data-bs-toggle="tooltip" data-bs-title="A skewed or altered perspective. Biased data refers to data that may be inaccurate or unevenly portrayed (usually in favour of specific variables) and is therefore not as robust.' (Kemp et al., 2022).">Biased<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a>  by movement speed (Palencia et al., 2021)</p></li>
<li><p class="sd-card-text">Best suited to larger animals; the smaller the focal species, the lower remote cameras must be set, which reduces the depth of the viewshed, and thus sampling size and the flexibility of the model’ (Howe et al., 2017; Clarke et al., 2023).</p></li>
<li><p class="sd-card-text">Does not permit inference about spatial variation in <a href="09_glossary.html#obj_abundance" target="_blank" data-bs-toggle="tooltip" data-bs-title="The number of individuals in a population (Wearn & Glover-Kapfer, 2017).">abundance<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a>  (unless using hierarchical distance which can model spatial variation as a function of covariates) (Gilbert et al., 2020; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Calculating camera-animal distances can be labour-intensive and time-consuming (however, recently developed techniques (e.g., Johanns et al., 2022) show promise for simplifying and automating the process) (Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Requires a good understanding of the focal populations’ activity patterns;  estimates can be biased (e.g., under-estimated) when regular periods of inactivity are not accounted for (using detection times to infer periods of activity may help overcome this limitation)’ (Howe et al., 2017; Palencia et al., 2021; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">Tends to underestimate  (Howe et al., 2017; Twining et al., 2022; Clarke et al., 2023)</p></li>
<li><p class="sd-card-text">{{ mod_ds_con_08 }</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</details><div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Overview</label><div class="sd-tab-content docutils">
<p>This section will be available soon! In the meantime, check out the information in the other tabs!</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/00_coming_soon.png"><img alt="../_images/00_coming_soon.png" src="../_images/00_coming_soon.png" style="width: 300px;" /></a>
</figure>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
In-depth</label><div class="sd-tab-content docutils">
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>This content was adapted from: The Density Handbook</strong>, “<a class="reference external" href="https://www.researchgate.net/publication/368601884_Using_Camera_Traps_to_Estimate_Medium_and_Large_Mammal_Density_Comparison_of_Methods_and_Recommendations_for_Wildlife_Managers">Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</a>” (Clarke et al., 2023)</p>
</div>
<p>Distance sampling (DS) theory was developed in the early 1990s to estimate density from line- or point-transect surveys, including aerial surveys (e.g., Alberta Environment and Parks. (2016). <em>Aerial Ungulate Surveys using Distance Sampling Techniques Protocol Manual.</em> <a class="reference external" href="https://open.alberta.ca/dataset/71c53d7b-0802-4800-9f95-0520b64b63c2/resource/ee933caa-bfc7-4334-a4d0-6085ebf198e7/download/aep-aerial-ungulate-surveys-using-distance-sampling-2016.pdf">https://open.alberta.ca/dataset/71c53d7b-0802-4800-9f95-0520b64b63c2/resource/ee933caa-bfc7-4334-a4d0-6085ebf198e7/download/aep-aerial-ungulate-surveys-using-distance-sampling-2016.pdf</a>; Buckland et al., 1998). The novelty of the DS approach is in its capacity to correct for imperfect detection (i.e., not observing animals that are present) by measuring the distance between survey lines or points and animals (Morin et al., 2022; Buckland et al., 2015; Gilbert et al., 2020).</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_fig6_clipped.png"><img alt="../_images/clarke_et_al_2023_fig6_clipped.png" src="../_images/clarke_et_al_2023_fig6_clipped.png" style="width: 150px;" /></a>
</figure>
<blockquote>
<div><p><strong>Clarke et al. (2023) - Fig. 6</strong> An example detection function. The probability of detecting an animal decreases with increasing distance from the observer.</p>
</div></blockquote>
<p>The DS model was adapted for use with camera trap data by Howe et al. (2017). Camera trap DS capitalizes on the similarities between camera trap surveys and human-observer point transect surveys – for example, both cameras and people tabulate the number of animals seen in a “snapshot” moment from a point in space (Buckland, 2006). There are, however, important differences to account for. For one: in human-observer studies, a point is sampled for an instant, and only one or a few times total; a camera, in contrast, samples the same point for a long period of time (Palencia et al., 2021). For another: human observers can pivot 360º around a point to count animals, while cameras are fixed in place and sample only a fraction of a circle (Howe et al., 2017). Camera trap DS must therefore include inputs of time and viewshed angle. The equation derived by Howe et al. (2017) is:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_ds1.png"><img alt="../_images/clarke_et_al_2023_eqn_ds1.png" src="../_images/clarke_et_al_2023_eqn_ds1.png" style="width: 150px;" /></a>
</figure>
<p>where <em>𝑌</em> is the number of detection events, 𝑤 is the truncation distance (i.e., the distance beyond which animal-camera distances are no longer considered), <em>𝑒</em> is the sampling effort, and <em>𝑝</em> is the probability of capturing an image of an animal within distance <em>𝑤</em> (Howe et al., 2017).</p>
<p><strong>To calculate sampling effort <em>𝑒</em>:</strong> let us first consider temporal effort. At a given camera, temporal effort is a function of the camera’s total sampling time <em>𝐻</em> and a predetermined interval <em>𝑡</em> units of time apart, at which the distance between camera and animal(s) is measured, such that temporal effort at the camera is <em>𝐻</em>/<em>𝑡</em> (Howe et al., 2017). If that same camera has a viewshed angle of 𝜃 radians, the fraction of a circle it samples is 𝜃 / 2π.</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_ds2.png"><img alt="../_images/clarke_et_al_2023_eqn_ds2.png" src="../_images/clarke_et_al_2023_eqn_ds2.png" style="width: 150px;" /></a>
</figure>
<p>Taken together, sampling effort can therefore be expressed as:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_ds3.png"><img alt="../_images/clarke_et_al_2023_eqn_ds3.png" src="../_images/clarke_et_al_2023_eqn_ds3.png" style="width: 150px;" /></a>
</figure>
<p><strong>To estimate the probability of capturing an animal <em>𝑝</em>:</strong> practitioners must estimate the horizontal distance <em>𝑟</em> between a camera and the centre of every animal detected, at each snapshot moment <em>𝑡</em> intervals apart, for as long as animals are within the viewshed (Howe et al., 2017). Howe et al. (2017) recommend a <em>𝑡</em> of 0.25 to 3 seconds; if the focal species is fast-moving or rare, and/or cameras have fast trigger speeds, practitioners should use a smaller <em>𝑡</em>. Measurements of <em>𝑟</em> can then be inputted into a detection function, <em>𝑓</em>(<em>𝑟</em>), which describes the probability an animal at distance <em>𝑟</em> is detected given 0 ≤ <em>𝑟</em> ≤ <em>𝑤</em> – producing an estimate of <em>𝑝</em> (Buckland et al., 2015).</p>
<p>Options for measuring camera-animal distance <em>𝑟</em> include: 1) comparing images of animals to reference images of field crew or objects at known distances from the camera (manually or automated; Haucke et al., 2022, Howe et al., 2017); 2) placing permanent reference objects at known distances from the camera so they are visible in every capture (Palencia et al., 2021); 3) physically measuring out camera-animal distances in the field, using animal images as references (Rowcliffe et al., 2011); and 4) a recently-developed, fully-automated approach (<a class="github reference external" href="https://github.com/PJcs/DistanceEstimationTracking">PJcs/DistanceEstimationTracking</a>) which does not require reference images or objects (Johanns et al., 2022).</p>
<p>If the species of interest is regularly and predictably inactive (e.g., rests at night), estimates of density must be corrected for activity level to minimize bias (Howe et al., 2017; Palencia et al., 2021). Practitioners may choose to set total sampling time <em>𝐻</em> as the time the study population was active and available for detection; another option is to correct density 𝐷** for the proportion of time animals are active, such that:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_ds4.png"><img alt="../_images/clarke_et_al_2023_eqn_ds4.png" src="../_images/clarke_et_al_2023_eqn_ds4.png" style="width: 150px;" /></a>
</figure>
<p>where <em>𝐷<sub>𝐶</sub></em> is the corrected density estimate and 𝑎 is activity level (Howe et al., 2017; Palencia et al., 2021). Activity level is determined as per Rowcliffe et al. (2014).</p>
<h2 class="rubric" id="simulations-field-experiments">Simulations &amp; Field Experiments</h2>
<p>Howe et al. (2017) ran simulations of “complex” animal movement patterns (i.e., animals moved with variable speeds, meandered, and rested periodically), and found that, when periods of rest were excluded from analyses, the DS model produced unbiased and precise estimates of density (CV / 0.10). When periods of rest were included, in contrast, DS performed poorly and inconsistently – whether animals rested within the viewshed or outside of the viewshed (i.e., were not detected). Animal activity patterns should therefore be considered when implementing the DS model; practitioners should have a strong understanding of when their species of interest is active versus inactive. Note that population and camera trap densities were both quite high in this simulation – 10 animals/km<sup>2</sup> and 6.25 camera traps/km<sup>2</sup> (Howe et al., 2017).</p>
<p>In northwestern Africa, camera trap DS produced higher estimates of duiker density than line-transect surveys – a method generally thought to underestimate the densities of forest-dwelling ungulates (Howe et al., 2017). The researchers collected video data.</p>
<p>Another study in northwestern Africa found that the DS model performed variably for different species (Cappelle et al., 2021). DS density estimates of a common ungulate – duiker – were comparable to previous estimates (line-transect surveys and Howe et al.’s (2017) camera trap DS study), and similarly precise. For semi-arboreal chimpanzees, DS-derived density estimates were biased low and depended greatly on measures of activity level (i.e., the proportion of the day chimpanzees were on the ground and available for detection). Compared with other studies:</p>
<ul class="simple">
<li><p>DS performed inferiorly to spatial capture-recapture (SCR; see section <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_11_mod_scr_secr.html"><span>Spatial capture-recapture (SCR) / Spatially explicit capture recapture (SECR)</span></a>) with individual identification (Després‐Einspenner et al., 2017, Cappelle et al., 2019).</p></li>
<li><p>DS estimates were, however, comparable to labour-intensive line-transect nest surveys.
The DS model performed inconsistently for rare species in this system, producing reasonable estimates of leopard density but questionable estimates of elephant density.</p></li>
</ul>
<p>DS-derived leopard density was similar to a previous study combining collar, camera and track data (Cappelle et al., 2021, Jenny, 1996). DS-derived elephant density was nearly double that from previous line-transect surveys and extremely imprecise (0.60 &lt; CV &lt; 2.00; Cappelle et al., 2021). As per Howe et al. (2017), videos were also used for this study.</p>
<p>Palencia et al. (2021) used DS to estimate the densities of red deer and boar. They found that the model performed similarly to the random encounter model (REM; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_17_mod_rem.html"><span>Random encounter model [REM]</span></a>) and the random encounter and staying time model (REST; see <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_18_mod_rest.html"><span>Random encounter and staying time [REST]</span></a>) for both species. Compared to independent density estimates (line-transect distance sampling for red deer, drive counts for boar): DS yielded a comparable density for deer but underestimated density for boar, perhaps due to slow camera recovery times (Palencia et al., 2021). Precision of camera trap DS was quite low, with an average CV of 0.42. Still images were used.</p>
<p>Bessone et al. (2020) used camera trap DS to estimate the densities of 14 vertebrate species, finding that low population density and reactivity to cameras were major sources of bias, and that the model applied best to evenly-distributed (versus clumpilydistributed) populations. Precision was highest for common, high-density species, but satisfactory (i.e., CV &lt; 0.35) for rare-but-widely-distributed species.
Finally, another density methods comparison study showed that camera trap DS was more precise than genetic mark-recapture, live capture-recapture, REM, and spatial count (SC; see section <a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_14_mod_sc.html"><span>Spatial count</span></a>) for pine marten (CV = 0.34; Twining et al., 2022). While all methods produced densities within accepted ranges, DS tended to underestimate density (Twining et al., 2022).</p>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
Visual resources</label><div class="sd-tab-content docutils">
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_fig6_clipped.png" class="img-grid" src="../_images/clarke_et_al_2023_fig6_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Clarke et al. (2023) - Fig. 6</strong> An example detection function. The probability of detecting an animal decreases with increasing distance from the observer.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_ds1.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_ds1.png" />
</figure>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_ds2.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_ds2.png" />
</figure>
</div>
</div>
</div>
</div>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_ds3.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_ds3.png" />
</figure>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Clarke et al., 2023</div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_eqn_ds4.png" class="img-grid" src="../_images/clarke_et_al_2023_eqn_ds4.png" />
</figure>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
rtxt_figure6_ref_id</div>
<figure class="align-default">
<img alt="../_images/figure6_filename.png" class="img-grid" src="../_images/figure6_filename.png" />
</figure>
<p class="sd-card-text">figure6_caption</p>
</div>
</div>
</div>
</div>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
rtxt_figure7_ref_id</div>
<figure class="align-default">
<img alt="../_images/figure7_filename.png" class="img-grid" src="../_images/figure7_filename.png" />
</figure>
<p class="sd-card-text">figure7_caption</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
rtxt_figure8_ref_id</div>
<figure class="align-default">
<img alt="../_images/figure8_filename.png" class="img-grid" src="../_images/figure8_filename.png" />
</figure>
<p class="sd-card-text">figure8_caption</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
rtxt_figure9_ref_id</div>
<figure class="align-default">
<img alt="../_images/figure9_filename.png" class="img-grid" src="../_images/figure9_filename.png" />
</figure>
<p class="sd-card-text">figure9_caption</p>
</div>
</div>
</div>
</div>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-m-0 sd-p-0 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-1 sd-g-xs-1 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
rtxt_vid1_ref_id</div>
<div><div style="position:relative;padding-top:56.25%;"><iframe src="vid1_url" loading="lazy" frameborder="0" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>  </div></div>
<p class="sd-card-text">vid1_caption</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
rtxt_vid2_ref_id</div>
<div><div style="position:relative;padding-top:56.25%;"><iframe src="vid2_url" loading="lazy" frameborder="0" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>  </div></div>
<p class="sd-card-text">vid2_caption</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
rtxt_vid3_ref_id</div>
<div><div style="position:relative;padding-top:56.25%;"><iframe src="vid3_url" loading="lazy" frameborder="0" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>  </div></div>
<p class="sd-card-text">vid3_caption</p>
</div>
</div>
</div>
</div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-3">
Shiny apps/Widgets</label><div class="sd-tab-content docutils">
<p>Check back in the future!</p>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-4">
Analytical tools &amp; Resources</label><div class="sd-tab-content docutils">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Type</p></th>
<th class="head text-left"><p>Name</p></th>
<th class="head text-left"><p>Note</p></th>
<th class="head text-left"><p>URL</p></th>
<th class="head text-left"><p>Reference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Online book</p></td>
<td class="text-left"><p>Distance Sampling: Estimating Abundance of Biological Populations (1993)</p></td>
<td class="text-left"><p></p></td>
<td class="text-left"><p><a class="reference external" href="https://distancesampling.org/downloads/distancebook1993/index.html">https://distancesampling.org/downloads/distancebook1993/index.html</a></p></td>
<td class="text-left"><p>Buckland, S. T., D.R. Anderson, K.P. Burnham, &amp; J.L. Laake. (1998). <em>Distance Sampling: Estimating Abundance of Biological Populations</em>. Chapman &amp; Hall, London. <a class="reference external" href="https://doi.org/10.1007/978-94-011-1574-2">https://doi.org/10.1007/978-94-011-1574-2</a></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource2_type</p></td>
<td class="text-left"><p>resource2_name</p></td>
<td class="text-left"><p>resource2_note</p></td>
<td class="text-left"><p>resource2_url</p></td>
<td class="text-left"><p>rbib_resource2_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource3_type</p></td>
<td class="text-left"><p>resource3_name</p></td>
<td class="text-left"><p>resource3_note</p></td>
<td class="text-left"><p>resource3_url</p></td>
<td class="text-left"><p>rbib_resource3_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource4_type</p></td>
<td class="text-left"><p>resource4_name</p></td>
<td class="text-left"><p>resource4_note</p></td>
<td class="text-left"><p>resource4_url</p></td>
<td class="text-left"><p>rbib_resource4_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource5_type</p></td>
<td class="text-left"><p>resource5_name</p></td>
<td class="text-left"><p>resource5_note</p></td>
<td class="text-left"><p>resource5_url</p></td>
<td class="text-left"><p>rbib_resource5_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource6_type</p></td>
<td class="text-left"><p>resource6_name</p></td>
<td class="text-left"><p>resource6_note</p></td>
<td class="text-left"><p>resource6_url</p></td>
<td class="text-left"><p>rbib_resource6_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource7_type</p></td>
<td class="text-left"><p>resource7_name</p></td>
<td class="text-left"><p>resource7_note</p></td>
<td class="text-left"><p>resource7_url</p></td>
<td class="text-left"><p>rbib_resource7_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource8_type</p></td>
<td class="text-left"><p>resource8_name</p></td>
<td class="text-left"><p>resource8_note</p></td>
<td class="text-left"><p>resource8_url</p></td>
<td class="text-left"><p>rbib_resource8_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource9_type</p></td>
<td class="text-left"><p>resource9_name</p></td>
<td class="text-left"><p>resource9_note</p></td>
<td class="text-left"><p>resource9_url</p></td>
<td class="text-left"><p>rbib_resource9_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource10_type</p></td>
<td class="text-left"><p>resource10_name</p></td>
<td class="text-left"><p>resource10_note</p></td>
<td class="text-left"><p>resource10_url</p></td>
<td class="text-left"><p>rbib_resource10_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource11_type</p></td>
<td class="text-left"><p>resource11_name</p></td>
<td class="text-left"><p>resource11_note</p></td>
<td class="text-left"><p>resource11_url</p></td>
<td class="text-left"><p>rbib_resource11_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource12_type</p></td>
<td class="text-left"><p>resource12_name</p></td>
<td class="text-left"><p>resource12_note</p></td>
<td class="text-left"><p>resource12_url</p></td>
<td class="text-left"><p>rbib_resource12_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource13_type</p></td>
<td class="text-left"><p>resource13_name</p></td>
<td class="text-left"><p>resource13_note</p></td>
<td class="text-left"><p>resource13_url</p></td>
<td class="text-left"><p>rbib_resource13_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource14_type</p></td>
<td class="text-left"><p>resource14_name</p></td>
<td class="text-left"><p>resource14_note</p></td>
<td class="text-left"><p>resource14_url</p></td>
<td class="text-left"><p>rbib_resource14_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource15_type</p></td>
<td class="text-left"><p>resource15_name</p></td>
<td class="text-left"><p>resource15_note</p></td>
<td class="text-left"><p>resource15_url</p></td>
<td class="text-left"><p>rbib_resource15_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource16_type</p></td>
<td class="text-left"><p>resource16_name</p></td>
<td class="text-left"><p>resource16_note</p></td>
<td class="text-left"><p>resource16_url</p></td>
<td class="text-left"><p>rbib_resource16_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource17_type</p></td>
<td class="text-left"><p>resource17_name</p></td>
<td class="text-left"><p>resource17_note</p></td>
<td class="text-left"><p>resource17_url</p></td>
<td class="text-left"><p>rbib_resource17_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource18_type</p></td>
<td class="text-left"><p>resource18_name</p></td>
<td class="text-left"><p>resource18_note</p></td>
<td class="text-left"><p>resource18_url</p></td>
<td class="text-left"><p>rbib_resource18_ref_id</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>resource19_type</p></td>
<td class="text-left"><p>resource19_name</p></td>
<td class="text-left"><p>resource19_note</p></td>
<td class="text-left"><p>resource19_url</p></td>
<td class="text-left"><p>rbib_resource19_ref_id</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>resource20_type</p></td>
<td class="text-left"><p>resource20_name</p></td>
<td class="text-left"><p>resource20_note</p></td>
<td class="text-left"><p>resource20_url</p></td>
<td class="text-left"><p>rbib_resource20_ref_id</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-5">
References</label><div class="sd-tab-content docutils">
<p>Alberta Environment and Parks. (2016). <em>Aerial Ungulate Surveys using Distance Sampling Techniques Protocol Manual.</em> <a class="reference external" href="https://open.alberta.ca/dataset/71c53d7b-0802-4800-9f95-0520b64b63c2/resource/ee933caa-bfc7-4334-a4d0-6085ebf198e7/download/aep-aerial-ungulate-surveys-using-distance-sampling-2016.pdf">https://open.alberta.ca/dataset/71c53d7b-0802-4800-9f95-0520b64b63c2/resource/ee933caa-bfc7-4334-a4d0-6085ebf198e7/download/aep-aerial-ungulate-surveys-using-distance-sampling-2016.pdf</a></p>
<p>Clarke, J., Bohm, H., Burton, C., Constantinou, A. (2023). <em>Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</em>. <a class="reference external" href="https://doi.org/10.13140/RG.2.2.18364.72320">https://doi.org/10.13140/RG.2.2.18364.72320</a></p>
<p>Bessone, M., Kühl, H. S., Hohmann, G., Herbinger, I., N’Goran, K. P., Asanzi, P., Da Costa, P. B., Dérozier, V., Fotsing, E. D. B., Beka, B. I., Iyomi, M. D., Iyatshi, I. B., Kafando, P., Kambere, M. A., Moundzoho, D. B., Wanzalire, M. L. K., Fruth, B., &amp; Michalski, F. (2020). Drawn out of the Shadows: Surveying Secretive Forest Species with Camera Trap Distance Sampling. <em>Journal of Applied Ecology, 57</em>(5), 963-974. <a class="reference external" href="https://doi.org/10.1111/1365-2664.13602">https://doi.org/10.1111/1365-2664.13602</a></p>
<p>Clarke, J., Bohm, H., Burton, C., Constantinou, A. (2023). <em>Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</em>. <a class="reference external" href="https://doi.org/10.13140/RG.2.2.18364.72320">https://doi.org/10.13140/RG.2.2.18364.72320</a></p>
<p>Buckland, S. T., D.R. Anderson, K.P. Burnham, &amp; J.L. Laake. (1998). <em>Distance Sampling: Estimating Abundance of Biological Populations</em>. Chapman &amp; Hall, London. <a class="reference external" href="https://doi.org/10.1007/978-94-011-1574-2">https://doi.org/10.1007/978-94-011-1574-2</a></p>
<p>Buckland, S. T., E. A. Rexstad, T. A. Marques, C. S. Oedekoven. (2015). <em>Mathematics and Statistics. Distance Sampling: Methods and Applications.</em> Springer International Publishing. <a class="reference external" href="https://doi.org/10.1007/978-3-319-19219-2">https://doi.org/10.1007/978-3-319-19219-2</a></p>
<p>Cappelle, N., Howe, E. J., Boesch, C., &amp; Kühl, H. S. (2021). Estimating Animal Abundance and Effort-Precision Relationship with Camera Trap Distance Sampling. <em>Ecosphere, 12</em>(1). <a class="reference external" href="https://doi.org/10.1002/ecs2.3299">https://doi.org/10.1002/ecs2.3299</a></p>
<p>Després‐Einspenner, M., Howe, E. J., Drapeau, P., &amp; Kühl, H. S. (2017). An empirical evaluation of camera trapping and spatially explicit capture‐recapture models for estimating chimpanzee density. <em>American Journal of Primatology, 79</em>(7), e22647. <a class="reference external" href="https://doi.org/10.1002/ajp.22647">https://doi.org/10.1002/ajp.22647</a></p>
<p>Gilbert, N. A., Clare, J. D. J., Stenglein, J. L., &amp; Zuckerberg, B. (2020). Abundance Estimation of Unmarked Animals based on Camera-Trap Data. <em>Conservation Biology, 35</em>(1), 88-100. <a class="reference external" href="https://doi.org/10.1111/cobi.13517">https://doi.org/10.1111/cobi.13517</a></p>
<p>Haucke, T., Kühl, H. S., Hoyer, J., &amp; Steinhage, V. (2022). Overcoming the distance estimation bottleneck in estimating animal abundance with camera traps. <em>Ecological Informatics, 68</em>, 101536. <a class="reference external" href="https://doi.org/10.1016/j.ecoinf.2021.101536">https://doi.org/10.1016/j.ecoinf.2021.101536</a></p>
<p>Howe, E. J., Buckland, S. T., Després-Einspenner, M. -L., &amp; Kühl, H. S. (2017). Distance sampling with camera traps. <em>Methods in Ecology and Evolution, 8</em>(11), 1558-1565. <a class="reference external" href="https://doi.org/https://doi.org/10.1111/2041-210X.12790">https://doi.org/https://doi.org/10.1111/2041-210X.12790</a></p>
<p>Jenny, D. (1996). Spatial organization of leopards Panthera pardus in Taï National Park, Ivory Coast: Is rainforest habitat a ‘tropical haven’? <em>Journal of Zoology, 240</em>(3), 427-440. <a class="reference external" href="https://doi.org/10.1111/j.1469-7998.1996.tb05296.x">https://doi.org/10.1111/j.1469-7998.1996.tb05296.x</a></p>
<p>Morin, D. J., Boulanger, J., Bischof, R., Lee, D. C., Ngoprasert, D., Fuller, A. K., McLellan, B., Steinmetz, R., Sharma, S., Garshelis, D., Gopalaswamy, A., Nawaz, M. A., &amp; Karanth, U. (2022).comparison of methods for estimating Density and population trends for low-Density Asian bears. <em>Global Ecology and Conservation, 35</em>, e02058 <a class="reference external" href="https://doi.org/10.1016/j.gecco.2022.e02058">https://doi.org/10.1016/j.gecco.2022.e02058</a></p>
<p>Palencia, P., Rowcliffe, J. M., Vicente, J., &amp; Acevedo, P. (2021). Assessing the camera trap methodologies used to estimate Density of unmarked populations. <em>Journal of Applied Ecology, 58</em>(8), 1583-1592. <a class="reference external" href="https://doi.org/10.1111/1365-2664.13913">https://doi.org/10.1111/1365-2664.13913</a></p>
<p>Rowcliffe, M. J., Carbone, C., Jansen, P. A., Kays, R., &amp; Kranstauber, B. (2011). Quantifying the sensitivity of camera traps: an adapted distance sampling approach. <em>Methods in Ecology and Evolution, 2</em>(5), 464-476. <a class="reference external" href="https://doi.org/10.1111/j.2041-210X.2011.00094.x">https://doi.org/10.1111/j.2041-210X.2011.00094.x</a></p>
<p>Twining, J. P., McFarlane, C., O’Meara, D., O’Reilly, C., Reyne, M., Montgomery, W. I., Helyar, S., Tosh, D. G., &amp; Augustine, B. C. (2022) A Comparison of Density Estimation Methods for Monitoring Marked and Unmarked Animal Populations. <em>Ecosphere, 13</em>(10), e4165. <a class="reference external" href="https://doi.org/10.1002/ecs2.4165">https://doi.org/10.1002/ecs2.4165</a></p>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              
              
              
              
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>