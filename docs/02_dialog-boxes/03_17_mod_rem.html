
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Random encounter model (REM) &#8212; Remote Camera Decision Support Tool - Concept Library</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=9bd6c0e5" />
    <link rel="stylesheet" type="text/css" href="../_static/scratch_backup.css?v=ed3b7673" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/03_17_mod_rem';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Remote Camera Decision Support Tool - Concept Library - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="Remote Camera Decision Support Tool - Concept Library - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool">
    <b>Home</b> 
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/">
    Concept library
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/08_references.html">
    References
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/09_glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/10_other_resource_lib.html">
    Other resources
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/AB-RCSC/rc-decision-support-tool" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github-square fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://ab-rcsc.github.io/RCSC-WildCAM_Remote-Camera-Survey-Guidelines-and-Metadata-Standards/" title="Survey Guidelines / Metadata Standards" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="../_static/logo_survguide_metadata.png" class="icon-link-image" alt="Survey Guidelines / Metadata Standards"/></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/02_dialog-boxes/03_17_mod_rem.md"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool">
    <b>Home</b> 
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/">
    Concept library
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/08_references.html">
    References
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/09_glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/10_other_resource_lib.html">
    Other resources
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/AB-RCSC/rc-decision-support-tool" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github-square fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://ab-rcsc.github.io/RCSC-WildCAM_Remote-Camera-Survey-Guidelines-and-Metadata-Standards/" title="Survey Guidelines / Metadata Standards" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="../_static/logo_survguide_metadata.png" class="icon-link-image" alt="Survey Guidelines / Metadata Standards"/></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/02_dialog-boxes/03_17_mod_rem.md"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="random-encounter-model-rem">
<span id="i-mod-rem"></span><h1>Random encounter model (REM)<a class="headerlink" href="#random-encounter-model-rem" title="Link to this heading">#</a></h1>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/09_viewshed_dens_est.html"><span>Viewshed density estimators</span></a></p>
<p><a class="sd-sphinx-override sd-badge sd-outline-primary sd-text-primary reference external" href="https://ab-rcsc.github.io/rc-decision-support-tool_concept-library/02_dialog-boxes/03_18_mod_rest.html"><span>Random encounter and staying time [REST]</span></a></p>
</div>
</div>
<div class="docutils">
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Assumptions, Pros, Cons</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Assumptions</div>
<ul class="simple">
<li><p class="sd-card-text">Demographic closure (<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>; <a href="./08_references.html#doran_myers_2018" target="_blank">Doran-Myers, 2018</a>) (i.e., no births or deaths)</p></li>
<li><p class="sd-card-text">Geographic closure (<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>; <a href="./08_references.html#doran_myers_2018" target="_blank">Doran-Myers, 2018</a>) (i.e., no immigration or emigration) (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text"><a href="09_glossary.html#cam_location" target="_blank" data-bs-toggle="tooltip" data-bs-title="Camera location: The location where a single camera was placed (recorded as 'Camera Location Name').">Camera locations<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> are <a href="09_glossary.html#sampledesign_random" target="_blank" data-bs-toggle="tooltip" data-bs-title="Random (or 'simple random') design: Cameras occur at randomized camera locations (or sample stations) across the area of interest, sometimes with a predetermined minimum distance between camera locations (or sample stations).">randomly placed<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> relative to animal movement (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>; <a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>)</p></li>
<li><p class="sd-card-text">Animal movement is unaffected by the cameras (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>; <a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>)</p></li>
<li><p class="sd-card-text"><a href="09_glossary.html#accurate" target="_blank" data-bs-toggle="tooltip" data-bs-title="Accuracy: How close a measured or estimated value is to the true value' (Clarke et al., 2023).">Inaccurate<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> counts of independent ‚Äòcontacts‚Äô <a href="09_glossary.html#cam_location" target="_blank" data-bs-toggle="tooltip" data-bs-title="Camera location: The location where a single camera was placed (recorded as 'Camera Location Name').">camera locations<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>; <a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>)</p></li>
<li><p class="sd-card-text"><a href="09_glossary.html#bias" target="_blank" data-bs-toggle="tooltip" data-bs-title="Bias: A skewed or altered perspective. Biased data refers to data that may be inaccurate or unevenly portrayed (usually in favour of specific variables) and is therefore not as robust.' (Kemp et al., 2022).">Unbiased<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> estimates of animal activity levels and speed (<a href="./08_references.html#rowcliffe_et_al_2014" target="_blank">Rowcliffe et al., 2014</a>; <a href="./08_references.html#rowcliffe_et_al_2016" target="_blank">Rowcliffe et al., 2016</a>; <a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text">Camera‚Äôs <a href="09_glossary.html#detection_zone" target="_blank" data-bs-toggle="tooltip" data-bs-title="Detection zone: The area (conical in shape) in which a remote camera can detect the heat signature and motion of an object (Rovero & Zimmermann, 2016) (Figure 5).">detection zone<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> can be approximated well using a 2D cone shape, defined by the radius and angle parameters (<a href="./08_references.html#rowcliffe_et_al_2011" target="_blank">Rowcliffe et al., 2011</a>)</p></li>
<li><p class="sd-card-text">If activity and speed are to be estimated from camera data, two additional <a href="09_glossary.html#mod_assumption" target="_blank" data-bs-toggle="tooltip" data-bs-title="Model assumption: Explicitly stated (or implicitly premised) conventions, choices and other specifications (e.g., about the data, wildlife ecology*/behaviour, the relationships between variables, etc.) on which a particular modelling approach is based that allows the model to provide valid inference.">assumptions<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a>:</p>
<ul>
<li><p class="sd-card-text">All animals are active during the peak daily activity (<a href="./08_references.html#rowcliffe_et_al_2014" target="_blank">Rowcliffe et al., 2014</a>)</p></li>
<li><p class="sd-card-text">Animals moving quickly past a camera are not missed (<a href="./08_references.html#rowcliffe_et_al_2016" target="_blank">Rowcliffe et al., 2016</a>)</p></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Pros</div>
<ul class="simple">
<li><p class="sd-card-text">Flexible study design (e.g., ‚Äòholes‚Äô in grids allowed, camera spacing less important) (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text">Can be applied to <a href="09_glossary.html#typeid_unmarked" target="_blank" data-bs-toggle="tooltip" data-bs-title="Unmarked individuals / populations / species: Individuals, populations, or species (varies with modelling approach and context) that cannot be identified using natural or artificial markings (e.g., coat patterns, scars, tags, collars). Unmarked population models rely on supplementary data (e.g., animal movement speed) and*/or assumptions as a surrogate for individual identification; that is, to distinguish between multiple detections of the same individual from detections of multiple individuals when individuals do not have unique features (Gilbert et al., 2020; Morin et al., 2022).">unmarked<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> species (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text">Allows community-wide <a href="09_glossary.html#obj_density" target="_blank" data-bs-toggle="tooltip" data-bs-title="Density: The number of individuals per unit area (Wearn & Glover-Kapfer, 2017)">density<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> estimation (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text">Outputs also include informative parameter estimates (i.e., animal speed and activity levels, and <a href="09_glossary.html#detection_zone" target="_blank" data-bs-toggle="tooltip" data-bs-title="Detection zone: The area (conical in shape) in which a remote camera can detect the heat signature and motion of an object (Rovero & Zimmermann, 2016) (Figure 5).">detection zone<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> parameters) (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text">Comparable estimates to <a href="09_glossary.html#mod_secr" target="_blank" data-bs-toggle="tooltip" data-bs-title="Spatially explicit capture-recapture (SECR) / Spatial capture-recapture (SCR) (Borchers & Efford, 2008; Efford, 2004; Royle & Young, 2008; Royle et al., 2009): The SECR (or SCR) method is used to estimate the density of marked populations; an extension of traditional capture-recapture (CR; Karanth, 1995; Karanth & Nichols, 1998) models (Karanth, 1995; Karanth & Nichols, 1998) that explicitly accounts for camera location and animal movement (Burgar et al., 2018). SECR models use spatially referenced individual capture histories to infer where animals' home range centres are, assuming that detection probability decreases with increasing distance between cameras and home range centres (Clarke et al., 2023). SECR models can be implemented using different statistical frameworks, including Bayesian estimation (Royle and Young, 2008; Morin et al., 2022).">SECR<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> [(<a href="./08_references.html#efford_2004" target="_blank">Efford, 2004</a>; <a href="./08_references.html#borchers_efford_2008" target="_blank">Borchers &amp; Efford, 2008</a>; <a href="./08_references.html#royle_young_2008" target="_blank">Royle &amp; Young, 2008</a>; <a href="./08_references.html#royle_et_al_2009" target="_blank">Royle et al., 2009</a>) (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text">Does not require <a href="09_glossary.html#typeid_marked" target="_blank" data-bs-toggle="tooltip" data-bs-title="Marked individuals / populations / species: Individuals, populations, or species (varies with modelling approach and context) that can be identified using natural or artificial markings (e.g., coat patterns, scars, tags, collars).">marked<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> animals or identification of individuals (<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>; <a href="./08_references.html#doran_myers_2018" target="_blank">Doran-Myers, 2018</a>)</p></li>
<li><p class="sd-card-text">Can use camera spacing without regard to population  (<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>; <a href="./08_references.html#doran_myers_2018" target="_blank">Doran-Myers, 2018</a>)</p></li>
<li><p class="sd-card-text">Direct estimation of <a href="09_glossary.html#obj_density" target="_blank" data-bs-toggle="tooltip" data-bs-title="Density: The number of individuals per unit area (Wearn & Glover-Kapfer, 2017)">density<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a>; avoids ad-hoc definitions of study area (<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>)</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Cons</div>
<ul class="simple">
<li><p class="sd-card-text">Requires relatively stringent study design, particularly (e.g., <a href="09_glossary.html#sampledesign_random" target="_blank" data-bs-toggle="tooltip" data-bs-title="Random (or 'simple random') design: Cameras occur at randomized camera locations (or sample stations) across the area of interest, sometimes with a predetermined minimum distance between camera locations (or sample stations).">random<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> sampling and use of <a href="09_glossary.html#baitlure_bait" target="_blank" data-bs-toggle="tooltip" data-bs-title="Bait: A food item (or other substance) that is placed to attract animals via the sense of taste and olfactory cues (Schlexer, 2008).">bait<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> or <a href="09_glossary.html#baitlure_lure" target="_blank" data-bs-toggle="tooltip" data-bs-title="Lure: Any substance that draws animals closer; lures include scent (olfactory) lure, visual lure and audible lure (Schlexer, 2008).">lure<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a>) (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text">Requires independent estimates of animal speed or measurement of animal speed within videos (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text">No dedicated, simple software (<a href="./08_references.html#wearn_gloverkapfer_2017" target="_blank">Wearn &amp; Glover-Kapfer, 2017</a>)</p></li>
<li><p class="sd-card-text"><a href="09_glossary.html#sampledesign_random" target="_blank" data-bs-toggle="tooltip" data-bs-title="Random (or 'simple random') design: Cameras occur at randomized camera locations (or sample stations) across the area of interest, sometimes with a predetermined minimum distance between camera locations (or sample stations).">Random<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> relative to animal movement, grid preferred, avoid multiple captures of same individual, area coverage important for <a href="09_glossary.html#obj_abundance" target="_blank" data-bs-toggle="tooltip" data-bs-title="Absolute abundance / Population size: The number of individuals in a population (Wearn & Glover-Kapfer, 2017).">abundance<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> estimation (<a href="./08_references.html#rovero_et_al_2013" target="_blank">Rovero et al., 2013</a>)</p></li>
<li><p class="sd-card-text">Possible sources of error include <a href="09_glossary.html#accurate" target="_blank" data-bs-toggle="tooltip" data-bs-title="Accuracy: How close a measured or estimated value is to the true value' (Clarke et al., 2023).">inaccurate<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> measurement of <a href="09_glossary.html#detection_zone" target="_blank" data-bs-toggle="tooltip" data-bs-title="Detection zone: The area (conical in shape) in which a remote camera can detect the heat signature and motion of an object (Rovero & Zimmermann, 2016) (Figure 5).">detection zone<button type="button" class="btn btn-bd-tip-info-hidden btn-sm position-relative">.<span class="position-absolute top-0 start-100 translate-middle"><svg version="4.0.0.63c5cb3" width="10.0px" height="10.0px" class="sd-material-icon sd-material-icon-info sd-text-primary" viewBox="0 0 24 24" aria-hidden="true"><path d="M0 0h24v24H0z" fill="none"></path><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"></path></svg></span></button></a> and movement rate (<a href="./08_references.html#rowcliffe_et_al_2013" target="_blank">Rowcliffe et al., 2013</a>; <a href="./08_references.html#cusack_et_al_2015" target="_blank">Cusack et al., 2015</a>)</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</details><div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Overview</label><div class="sd-tab-content docutils">
<p>This section will be available soon! In the meantime, check out the information in the other tabs!</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/00_coming_soon.png"><img alt="../_images/00_coming_soon.png" src="../_images/00_coming_soon.png" style="width: 300px;" /></a>
</figure>
</div>
</div>
</div>
<div class="sd-tab-item docutils">
<p class="sd-tab-label rubric">In-depth</p>
<div class="sd-tab-content docutils">
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>This content was adapted from: The Density Handbook</strong>, ‚Äú<a class="reference external" href="https://www.researchgate.net/publication/368601884_Using_Camera_Traps_to_Estimate_Medium_and_Large_Mammal_Density_Comparison_of_Methods_and_Recommendations_for_Wildlife_Managers">Using Camera Traps to Estimate Medium and Large Mammal Density: Comparison of Methods and Recommendations for Wildlife Managers</a>‚Äù (Clarke et al., 2023)</p>
</div>
<p>The random encounter model (REM) treats animals like ideal gas particles ‚Äì that is, like randomly moving entities which are neither attracted to nor repelled by one another or landscape features (<a href="./08_references.html#gilbert_et_al_2020" target="_blank">Gilbert et al., 2020</a>; <a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>). If animals behave like ideal gas particles, the rate at which they ‚Äúbump into‚Äù and trigger camera traps is a function of animal movement, population density and the area within which cameras detect animals (<a href="./08_references.html#nakashima_et_al_2017" target="_blank">Nakashima et al., 2017</a>). So, the more animals move, the more animals in a population, or the larger the viewshed ‚Äì the more images will be captured (<a href="./08_references.html#palencia_et_al_2022" target="_blank">Palencia et al., 2022</a>). This relationship can be used to estimate density, such that:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_eqn_rem1.png"><img alt="../_images/clarke_et_al_2023_eqn_rem1.png" src="../_images/clarke_et_al_2023_eqn_rem1.png" style="width: 242.39999999999998px; height: 79.2px;" /></a>
</figure>
<p>where <em>ùëå</em> is the number of detection events, <em>ùëá</em> is the total sampling time and ùë£ is animal movement speed (or the distance travelled by an individual in a day); and <em>ùëü</em> and <em>ùúÉ</em>, the mean radius and angle of the detection zone (i.e., the area within which animals are detected with certainty) are used to calculate the area of the detection zone (<a href="./08_references.html#nakashima_et_al_2017" target="_blank">Nakashima et al., 2017</a>; <a href="./08_references.html#pettigrew_et_al_2021" target="_blank">Pettigrew et al., 2021</a>; <a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>).</p>
<p>Independent estimates of <em>ùë£</em> can be sourced from telemetric studies, estimated from intensive observation or calculated using camera trap data (<a href="./08_references.html#nakashima_et_al_2017" target="_blank">Nakashima et al., 2017</a>, <a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>, <a href="./08_references.html#rowcliffe_et_al_2016" target="_blank">Rowcliffe et al., 2016</a>). To calculate ùë£ using camera traps: for each observation, practitioners should determine how long it took the animal to pass through the viewshed (i.e., time between first and last image in a sequence), then measure the distance the animal travelled by either a) retracing their path in the field using photos as a guide or b) estimating their movement image-to-image during photo processing using markers (<a href="./08_references.html#pfeffer_et_al_2018" target="_blank">Pfeffer et al., 2018</a>, <a href="./08_references.html#rowcliffe_et_al_2016" target="_blank">Rowcliffe et al., 2016</a>).</p>
<p><em>ùëü</em> and <em>ùúÉ</em> can be measured in a few different ways. The first is by field trial: the detection zone is delineated by approaching the camera trap from different angles and at different speeds, recording where the sensor is triggered (Figure 7; <a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>). The second is using a distance sampling method described in Rowcliffe et al. (2011). The third is by setting a focal area of standard size and shape (i.e., of known ùëü and ùúÉ), within which detection is assumed to be perfect; only animals captured within the focal area are considered for analyses (<a href="./08_references.html#nakashima_et_al_2017" target="_blank">Nakashima et al., 2017</a>). <em>ùúÉ</em> may also be specified by the manufacturer (<a href="./08_references.html#pettigrew_et_al_2021" target="_blank">Pettigrew et al., 2021</a>).</p>
<p>When the species of interest travels in packs or herds, density as calculated per the equation above represents group density (i.e., the number of groups per unit area; <a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>). To convert group density to individual density, <em>ùê∑</em> must be multiplied by an independent estimate of average group size (<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>).</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/clarke_et_al_2023_fig7_clipped.png"><img alt="../_images/clarke_et_al_2023_fig7_clipped.png" src="../_images/clarke_et_al_2023_fig7_clipped.png" style="width: 117.0px; height: 125.39999999999999px;" /></a>
</figure>
<blockquote>
<div><p><strong>Clarke et al. (2023) - Fig. 7</strong> Measuring <em>ùëü</em> and <em>ùúÉ</em> by field trial. The perimeter of the detection zone is determined by approaching the camera from different angles and at different speeds, and noting where the camera‚Äôs sensor (red flash) detects motion (red dots).</p>
</div></blockquote>
<h2 class="rubric" id="simulations-and-field-experiments-clarke-et-al-2023">Simulations and Field Experiments (<a href="./08_references.html#clarke_et_al_2023" target="_blank">Clarke et al., 2023</a>)</h2>
<p>Of all the unmarked density models, the REM has undergone the most empirical testing (<a href="./08_references.html#palencia_et_al_2021" target="_blank">Palencia et al., 2021</a>). Rowcliffe et al. (2008) piloted the model in an enclosed animal park housing populations of known sizes, and found that the REM produced accurate density estimates for three out of four target species (two cervids and a marsupial). The model underestimated the density of the fourth species (a large rodent) because cameras were deployed in habitats it did not frequent ‚Äì a violation of assumption 3 (<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>).</p>
<p>The REM has proven robust in many study systems. Examples include:</p>
<ul class="simple">
<li><p>Palencia et al. (2021) found that the REM yielded similar density estimates as two non-camera methods, line-transect sampling and drive counts, for red deer and wild boar, respectively. The researchers also compared the REM to two other camera methods (random encounter and staying time (REST) and distance sampling (DS) models) ‚Äì of the three, the REM was the most consistent (<a href="./08_references.html#palencia_et_al_2021" target="_blank">Palencia et al., 2021</a>). In this study, animal movement speed <em>ùë£</em> was determined using camera trap data.</p></li>
<li><p>REM-derived density estimates of a mountain ungulate were highly consistent with visual count survey results (<a href="./08_references.html#kavcic_et_al_2021" target="_blank">Kavƒçiƒá et al., 2021</a>). Animal movement speed was measured using camera trap data (<a href="./08_references.html#kavcic_et_al_2021" target="_blank">Kavƒçiƒá et al., 2021</a>).</p></li>
<li><p>A study on black bears in Qu√©bec found that the REM produced comparable results to DNA mark-recapture using hair samples, but that REM estimates were less precise (<a href="./08_references.html#pettigrew_et_al_2021" target="_blank">Pettigrew et al., 2021</a>). The researchers estimated animal movement speed by averaging 19 years of telemetry data from four neighbouring black bear populations (<a href="./08_references.html#pettigrew_et_al_2021" target="_blank">Pettigrew et al., 2021</a>).</p></li>
<li><p>In the boreal forest of Washington state, REM and live-trapping spatial capturerecapture (SCR) produced similar density estimates for snowshoe hare (<a href="./08_references.html#jensen_et_al_2022" target="_blank">Jensen et al., 2022</a>). The REM and the REST performed identically in this system; both models outperformed the time-to-event (TTE) model (<a href="./08_references.html#jensen_et_al_2022" target="_blank">Jensen et al., 2022</a>). Measures of animal movement speed <em>ùë£</em> were pulled from camera data and combined with telemetry data from a study in the Yukon.</p></li>
<li><p>The REM yielded similar density estimates as, and was more precise than, livetrapping SCR at almost 90% of sampling sites in a study of hedgehogs (<a href="./08_references.html#schaus_et_al_2020" target="_blank">Schaus et al., 2020</a>). Moreover, the REM was powerful enough to detect a 25% population change in this system (<a href="./08_references.html#schaus_et_al_2020" target="_blank">Schaus et al., 2020</a>). Animal movement speed was estimated from camera trap images.</p></li>
</ul>
<p>The REM has also significantly over and underestimated the densities of natural populations. In Africa, for example, estimates of lioness density using the REM were significantly higher than from pride censuses (<a href="./08_references.html#cusack_et_al_2015" target="_blank">Cusack et al., 2015</a>). REM-derived densities skewed high because cameras were placed under shady trees, which attracted lions in the daytime (a violation of assumption 3), inflating the number of detection events <em>ùëå</em> (<a href="./08_references.html#cusack_et_al_2015" target="_blank">Cusack et al., 2015</a>). When only nighttime detections were considered, however, REM-derived densities did not differ significantly from censusderived densities (<a href="./08_references.html#cusack_et_al_2015" target="_blank">Cusack et al., 2015</a>). <em>ùë£</em>, animal movement speed, was determined via intensive observation. A study comparing the REM with fecal DNA mark-recapture found that the REM underestimated marten density by 60% or more (<a href="./08_references.html#balestrieri_et_al_2016" target="_blank">Balestrieri et al., 2016</a>). Animal movement speed ùë£ may have biased density low; the researchers estimated ùë£ from studies of pine marten occupying a different kind of habitat, where individuals may have moved more (<a href="./08_references.html#balestrieri_et_al_2016" target="_blank">Balestrieri et al., 2016</a>).</p>
<p>Simulations suggest that, to achieve adequate precision using the REM, a minimum of 20 to 40 camera stations should be deployed for as long as needed to collect at least 10 to 20 image sets (<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>). For populations with variable detection: about 100 cameras are needed to obtain a level of precision appropriate for wildlife management (coefficient of variation (CV) of 0.20 or less; <a href="./08_references.html#palencia_et_al_2021" target="_blank">Palencia et al., 2021</a>, <a href="./08_references.html#williams_et_al_2002" target="_blank">Williams et al., 2002</a>). To collect 10 to 20 image sets takes approximately 100 to 1,000 camera trap days for most mammal species; for rare species, cameras may need to be deployed for 1,000 camera trap days or more (<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a>).</p>
</div>
</div>
<div class="sd-tab-item docutils">
<p class="sd-tab-label rubric">Visual resources</p>
<div class="sd-tab-content docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<a href="./08_references.html#clarke_et_al_2023" target="_blank">Clarke et al., 2023</a></div>
<figure class="align-default">
<img alt="../_images/clarke_et_al_2023_fig7_clipped.png" class="img-grid" src="../_images/clarke_et_al_2023_fig7_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Clarke et al. (2023) - Fig. 7</strong> Measuring <em>ùëü</em> and <em>ùúÉ</em> by field trial. The perimeter of the detection zone is determined by approaching the camera from different angles and at different speeds, and noting where the camera‚Äôs sensor (red flash) detects motion (red dots).</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<a href="./08_references.html#henrich_et_al_2022" target="_blank">Henrich et al., 2022</a></div>
<figure class="align-default">
<img alt="../_images/henrich_et_al_2022_fig1_clipped.png" class="img-grid" src="../_images/henrich_et_al_2022_fig1_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Henrich et al. (2022) - Fig. 1</strong> Potential problems caused by animal behavior in the estimation of population densities of unmarked animal species using camera traps and our proposed solutions.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a></div>
<figure class="align-default">
<img alt="../_images/rowcliffe_et_al_2008_fig1_clipped.png" class="img-grid" src="../_images/rowcliffe_et_al_2008_fig1_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Rowcliffe et al. (2008) - Fig. 1</strong> Diagram illustrating the variation in profile presented to animals approaching from different angles by a segment-shaped camera trap detection zone.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-kebab-horizontal no-title" viewBox="0 0 24 24" aria-hidden="true"><path d="M20 14a2 2 0 1 1-.001-3.999A2 2 0 0 1 20 14ZM6 12a2 2 0 1 1-3.999.001A2 2 0 0 1 6 12Zm8 0a2 2 0 1 1-3.999.001A2 2 0 0 1 14 12Z"></path></svg></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Approach directions are indicated by arrows, the detection zone is the shaded segment, defined by radial distance r and angle Œ∏, and the profiles presented are indicated by heavy lines. Six limiting cases are shown for œÄ approach angles, with five resulting transitions. The angles opposite the profiles, Œ≥, are indicated for transitions 1, 2, 4 and 5 (the profile for transition 3 is constant so no such angle is required). The widths of profiles and ranges of Œ≥ for each transition are given by: transitions 1 and 5, 2r sin(Œ∏/2) sin(Œ≥), (œÄ ‚Äì Œ∏)/ 2 ‚â§ Œ≥ ‚â§ œÄ/2; transitions 2 and 4, r sin(Œ≥), Œ∏ ‚â§ Œ≥ ‚â§ œÄ/2; transition 3, r for Œ∏ approach angles.</p>
</div>
</details></div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a></div>
<figure class="align-default">
<img alt="../_images/rowcliffe_et_al_2008_fig4_clipped.png" class="img-grid" src="../_images/rowcliffe_et_al_2008_fig4_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Rowcliffe et al. (2008) - Fig. 4</strong> The precision of estimated density from simulated data in relation to variation in sampling effort, assuming high or low variance in camera trapping rate (upper and lower curves, respectively, in each graph).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-kebab-horizontal no-title" viewBox="0 0 24 24" aria-hidden="true"><path d="M20 14a2 2 0 1 1-.001-3.999A2 2 0 0 1 20 14ZM6 12a2 2 0 1 1-3.999.001A2 2 0 0 1 6 12Zm8 0a2 2 0 1 1-3.999.001A2 2 0 0 1 14 12Z"></path></svg></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Effort is varied as either (a) the number of cameras while holding time per camera constant; (b) the time per camera (indexed by the total number of photographs taken) while holding the number of cameras constant; and (c) the number of camera placements while holding the total amount of camera time constant.</p>
</div>
</details></div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<a href="./08_references.html#rowcliffe_et_al_2008" target="_blank">Rowcliffe et al., 2008</a></div>
<figure class="align-default">
<img alt="../_images/rowcliffe_et_al_2008_fig5_clipped.png" class="img-grid" src="../_images/rowcliffe_et_al_2008_fig5_clipped.png" />
</figure>
<p class="sd-card-text"><strong>Rowcliffe et al. (2008) - Fig. 5</strong> Expected trapping effort (camera days, indicated by contours) required to achieve 10 photographs given varying density and day range, assuming a group size of 1.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-kebab-horizontal no-title" viewBox="0 0 24 24" aria-hidden="true"><path d="M20 14a2 2 0 1 1-.001-3.999A2 2 0 0 1 20 14ZM6 12a2 2 0 1 1-3.999.001A2 2 0 0 1 6 12Zm8 0a2 2 0 1 1-3.999.001A2 2 0 0 1 14 12Z"></path></svg></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Typical combinations of day range and density are indicated for carnivores (C), ungulates (U) and rodents (R), calculated using allometric equations for day range and density at carrying capacity (see text) and illustrating densities between 10% and 100% of carrying capacity.</p>
</div>
</details></div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<a href="./08_references.html#palencia_enetwild_2022" target="_blank">Palencia &amp; Project ENETWILD, 2022</a></div>
<div class="iframe-container-vid"><iframe class="iframe-responsive-vid" src="https://www.youtube.com/embed/NUW4oLGeQwk?si=isAJ3uO31eANSkDv"></iframe></div>
<p class="sd-card-text">Camera Trap Methods for Density Estimation</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
rtxt_vid2_ref_id</div>
<div class="iframe-container-vid"><iframe class="iframe-responsive-vid" src="vid2_url"></iframe></div>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
rtxt_vid3_ref_id</div>
<div class="iframe-container-vid"><iframe class="iframe-responsive-vid" src="vid3_url"></iframe></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sd-tab-item docutils">
<p class="sd-tab-label rubric">Shiny apps/Widgets</p>
<div class="sd-tab-content docutils">
<p>Check back in the future!</p>
</div>
</div>
<div class="sd-tab-item docutils">
<p class="sd-tab-label rubric">Analytical tools &amp; Resources</p>
<div class="sd-tab-content docutils">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Type</p></th>
<th class="head text-left"><p>Name</p></th>
<th class="head text-left"><p>Note</p></th>
<th class="head text-left"><p>URL</p></th>
<th class="head text-left"><p>Reference</p></th>
</tr>
</thead>
</table>
</div>
<!-- END_RESOURCE_TABLE -->
</div>
</div>
<div class="sd-tab-item docutils">
<p class="sd-tab-label rubric">References</p>
<div class="sd-tab-content docutils">
<p>Balestrieri, A., Ruiz-Gonz√°lez, A., Vergara, M., Capelli, E., Tirozzi, P., Alfino, S., Minuti, G., Prigioni, C., &amp; Saino, N. (2016). Pine marten density in lowland riparian woods: A test of the Random Encounter Model based on genetic data. <em>Mammalian Biology, 81</em>(5), 439-446. <a class="reference external" href="https://doi.org/10.1016/j.mambio.2016.05.005">https://doi.org/10.1016/j.mambio.2016.05.005</a></p>
<p>Cusack, J., Dickman, A. J., Rowcliffe, J. M., Carbone, C., Macdonald, D. W., &amp; Coulson, T. (2015). Random versus Game Trail-based Camera trap Placement Strategy for Monitoring Terrestrial Mammal Communities. <em>PloS One</em>,<em>10</em>(5), e0126373. <a class="reference external" href="https://doi.org/10.1371/journal.pone.0126373">https://doi.org/10.1371/journal.pone.0126373</a></p>
<p>Gilbert, N. A., Clare, J. D. J., Stenglein, J. L., &amp; Zuckerberg, B. (2020). Abundance Estimation of Unmarked Animals based on Camera-Trap Data. <em>Conservation Biology, 35</em>(1), 88-100. <a class="reference external" href="https://doi.org/10.1111/cobi.13517">https://doi.org/10.1111/cobi.13517</a></p>
<p>Henrich, M., Hartig, F., Dormann, C. F., K√ºhl, H. S., Peters, W., Franke, F., Peterka, T., ≈†ustr, P., &amp; Heurich, M. (2022). Deer Behavior Affects Density Estimates With Camera Traps, but Is Outweighed by Spatial Variability. <em>Frontiers in Ecology and Evolution, 10</em>, 881502. <a class="reference external" href="https://doi.org/10.3389/fevo.2022.881502">https://doi.org/10.3389/fevo.2022.881502</a></p>
<p>Jensen, P. O., Wirsing, A. J., &amp; Thornton, D. H. (2022). Using camera traps to estimate density of snowshoe hare ( Lepus americanus ): A keystone boreal forest herbivore. <em>Journal of Mammalogy, 103</em>(3), 693-710. <a class="reference external" href="https://doi.org/10.1093/jmammal/gyac009">https://doi.org/10.1093/jmammal/gyac009</a></p>
<p>Kavƒçiƒá, K., Palencia, P., Apollonio, M., Vicente, J., &amp; ≈†prem, N. (2021). Random encounter model to estimate density of mountain-dwelling ungulate. <em>European Journal of Wildlife Research, 67</em>(5), 87. <a class="reference external" href="https://doi.org/10.1007/s10344-021-01530-1">https://doi.org/10.1007/s10344-021-01530-1</a></p>
<p>Nakashima, Y., Fukasawa, &amp; K., Samejima, H. (2017). Estimating Animal Density Without Individual Recognition Using Information Derivable Exclusively from Camera Traps. <em>Journal of Applied Ecology, 55</em>(2), 735-744. <a class="reference external" href="https://doi.org/10.1111/1365-2664.13059">https://doi.org/10.1111/1365-2664.13059</a></p>
<p>Palencia, P., Rowcliffe, J. M., Vicente, J., &amp; Acevedo, P. (2021). Assessing the camera trap methodologies used to estimate Density of unmarked populations. <em>Journal of Applied Ecology, 58</em>(8), 1583-1592. <a class="reference external" href="https://doi.org/10.1111/1365-2664.13913">https://doi.org/10.1111/1365-2664.13913</a></p>
<p>Palencia, P., Vicente, J., Soriguer, R. C., &amp; Acevedo, P. (2022). Towards a best‚Äêpractices guide for camera trapping: assessing differences among camera trap models and settings under field conditions. <em>Journal of Zoology, 316</em>(3), 197-208. <a class="reference external" href="https://doi.org/10.1111/jzo.12945">https://doi.org/10.1111/jzo.12945</a></p>
<p>Palencia, P. &amp; Project ENETWILD (2022, May 19). <em>Camera Trap Methods for Density Estimation.</em>  [Video]. YouTube. <a class="reference external" href="https://www.youtube.com/watch?v=NUW4oLGeQwk">https://www.youtube.com/watch?v=NUW4oLGeQwk</a></p>
<p>Pettigrew, P., Sigouin, D., &amp; St‚ÄêLaurent, M. (2021). Testing the precision and sensitivity of density estimates obtained with a camera‚Äêtrap method revealed limitations and opportunities. <em>Ecology and Evolution, 11</em>(12), 7879-7889. <a class="reference external" href="https://doi.org/10.1002/ece3.7619">https://doi.org/10.1002/ece3.7619</a></p>
<p>Pfeffer, S. E., Spitzer, R., Allen, A. M., Hofmeester, T. R., Ericsson, G., Widemo, F., Singh, N. J., &amp; Cromsigt, J. P. G. M. (2018). Pictures or pellets? Comparing camera trapping and dung counts as methods for estimating population densities of ungulates. <em>Remote Sensing in Ecology and Conservation, 4</em>(2), 173-183. <a class="reference external" href="https://doi.org/10.1002/rse2.67">https://doi.org/10.1002/rse2.67</a></p>
<p>Rowcliffe, J. M., Field, J., Turvey, S. T., &amp; Carbone, C. (2008). Estimating animal Density using camera traps without the need for individual recognition. <em>Journal of Applied Ecology</em>, <em>45</em>(4), 1228-1236. <a class="reference external" href="https://doi.org/10.1111/j.1365-2664.2008.01473.x">https://doi.org/10.1111/j.1365-2664.2008.01473.x</a></p>
<p>Rowcliffe, J. M., Jansen, P. A., Kays, R., Kranstauber, B., &amp; Carbone, C. (2016). Wildlife speed cameras: measuring animal travel speed and day range using camera traps. <em>Remote Sensing in Ecology and Conservation, 2</em>, 84-94. <a class="reference external" href="https://doi.org/10.1002/rse2.17">https://doi.org/10.1002/rse2.17</a></p>
<p>Schaus, J., Uzal, A., Gentle, L. K., Baker, P. J., Bearman‚ÄêBrown, L., Bullion, S., Gazzard, A., Lockwood, H., North, A., Reader, T., Scott, D. M., Sutherland, C. S., &amp; Yarnell, R. W. (2020). Application of the Random Encounter Model in citizen science projects to monitor animal densities. <em>Remote Sensing in Ecology and Conservation, 6</em>(4), 514-528. <a class="reference external" href="https://doi.org/10.1002/rse2.153">https://doi.org/10.1002/rse2.153</a></p>
<p>Williams, B. K., Nichols, J. D., &amp; Conroy, M. J. (2002). <em>Analysis and Management of Animal Populations: Modeling, Estimation, and Decision Making</em>. Book, Whole. San Diego: Academic Press. <a class="reference external" href="https://go.exlibris.link/qSfqP9dC">https://go.exlibris.link/qSfqP9dC</a></p>
</div>
</div>
<div class="docutils">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              
              
              
              
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>